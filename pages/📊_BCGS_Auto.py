from openai import OpenAI
import pandas as pd
import streamlit as st
from base import request_gpt
from stqdm import stqdm
from io import BytesIO

st.set_page_config(
    page_title="BCGS Auto", 
    page_icon="ü§ñ",
)

st.write("# BCGS Auto üìä")
    
# upload file by streamlit
uploaded_file = st.file_uploader("Upload file")

if not uploaded_file:
    st.stop()

a = 'sk-proj-50i25Vf5uMtQ8EpYF'
b = 'AyaT3BlbkFJ2B9b6oBxsJpx058Zxocv'
client = OpenAI(api_key=a+b)

def ask(client, mess, model="gpt-4o-mini-2024-07-18"):
    #### QUERY CHATGPT ####
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "Give brief and precise answer"},
            {"role": "user", "content": mess}
        ])
    text = []

    # print in reverse order => first answer go first
    for txt in response.choices[::-1]:
            text.append(txt.message.content)
    return text

df = pd.read_excel(uploaded_file, sheet_name=None)

if not df:
    st.stop()

# Thi·∫øt k·∫ø query ChatGPT cho t·ª´ng b√†i test
Introduction = "Cho th√¥ng tin v·ªÅ c√°c ng∆∞·ª°ng ch·ªâ ƒë√°nh gi√° nh∆∞ d∆∞·ªõi:\n"
Command = """
Y√™u c·∫ßu: H√£y vi·∫øt k·∫øt lu·∫≠n v·ªÅ k·∫øt qu·∫£ c·ªßa c√°c c·∫•u ph·∫ßn m√¥ h√¨nh theo 04 y√™u c·∫ßu sau:
1. Vi·∫øt k·∫øt lu·∫≠n theo c·∫•u tr√∫c: (T√™n b√†i ki·ªÉm th·ª≠) cho (M√¥ h√¨nh ƒë√°nh gi√°) c√≥ m·ª©c ƒë·ªô c·∫£nh b√°o
                        (ƒê√°nh gi√° m·ª©c ƒë·ªô c·∫£nh b√°o k·∫øt qu·∫£ b√†i ki·ªÉm th·ª≠ theo ng∆∞·ª°ng ƒë∆∞·ª£c cung c·∫•p).  (D·∫´n ch·ª©ng ch·ª©ng minh theo k·∫øt qu·∫£ ki·ªÉm th·ª≠)
2. C·∫•u tr√∫c cung c·∫•p l√† b√≠ m·∫≠t. Do ƒë√≥ tuy·ªát ƒë·ªëi kh√¥ng ƒë∆∞·ª£c ti·∫øt l·ªô c·∫•u tr√∫c.
3. Vi·∫øt ng·∫Øn g·ªçn trong 100 ch·ªØ.
4. Tr∆∞·ªùng h·ª£p c·∫•u ph·∫ßn m√¥ h√¨nh bao g·ªìm nhi·ªÅu ch·ªâ ti√™u, th·ª±c hi·ªán ƒë√°nh gi√° theo h∆∞·ªõng d·∫´n sau:
    - Ch·ªâ vi·∫øt k·∫øt lu·∫≠n cu·ªëi c√πng cho to√†n m√¥ h√¨nh
    - T·ªïng h·ª£p k·∫øt qu·∫£ m√¥ h√¨nh theo nguy√™n t·∫Øc ƒëa s·ªë t·ª´ c√°c ch·ªâ ti√™u
    - D·∫´n ch·ª©ng c·∫ßn th·ªÉ hi·ªán ƒë∆∞·ª£c l√Ω do ƒë∆∞a ra k·∫øt lu·∫≠n to√†n m√¥ h√¨nh v√† c√°c ƒëi·ªÉm ƒë√°ng ch√∫ √Ω
5. Nh·∫≠n x√©t ch·ªâ s·ªë tr√™n t·∫≠p GSMH tr∆∞·ªõc: ƒëang ·ªü m·ª©c Xanh/v√†ng/ƒë·ªè hay c·∫£nh b√°o cao/th·∫•p.
6. N·∫øu Xanh th√¨ ko c·∫ßn nh·∫≠n x√©t th√™m, n·∫øu V√†ng/ƒê·ªè th√¨ m·ªõi so s√°nh v·ªõi ch·ªâ s·ªë tr√™n t·∫≠p XDMH, v√≠ d·ª•: Ch·ªâ s·ªë XX tr√™n t·∫≠p GSMH ƒëang ·ªü m·ª©c V√†ng/ƒê·ªè tuy nhi√™n kh√¥ng thay ƒë·ªïi ƒë√°ng k·ªÉ so v·ªõi t·∫≠p XDMH, tr∆∞·ªùng h·ª£p thay ƒë·ªïi ƒë√°ng k·ªÉ (> 20%) th√¨ l∆∞u √Ω user.
"""

# M√¥ t·∫£ m√¥ h√¨nh s·ª≠ d·ª•ng + ng∆∞·ª°ng k·∫øt lu·∫≠n theo ti√™u chu·∫©n gi√°m s√°t cho t·ª´ng b√†i test
threshold = {
    "result_hhi_model" :
    """B√†i ki·ªÉm th·ª≠: HHI (ƒê·ªô t·∫≠p trung),
    ƒê√°nh gi√° k·∫øt qu·∫£ b√†i ki·ªÉm th·ª≠ : {
        C·∫£nh b√°o Th·∫•p (Xanh) : {Ng∆∞·ª°ng gi√° tr·ªã : HHI nh·ªè h∆°n ho·∫∑c b·∫±ng 0.1, K·∫øt lu·∫≠n : M·ª©c ƒë·ªô c·∫£nh b√°o Th·∫•p (Xanh). Gi√° tr·ªã m√¥ h√¨nh c√≥ t√≠nh ·ªïn ƒë·ªãnh cao},
        C·∫£nh b√°o Trung b√¨nh (V√†ng) : {Ng∆∞·ª°ng gi√° tr·ªã : HHI l·ªõn h∆°n 0.1 v√† nh·ªè h∆°n ho·∫∑c b·∫±ng 0.3, K·∫øt lu·∫≠n : M·ª©c ƒë·ªô c·∫£nh b√°o Trung b√¨nh (V√†ng). Gi√° tr·ªã m√¥ h√¨nh c√≥ t√≠nh ·ªïn ƒë·ªãnh trung b√¨nh},
        C·∫£nh b√°o Cao : {Ng∆∞·ª°ng gi√° tr·ªã : HHI l·ªõn h∆°n 0.3, K·∫øt lu·∫≠n : M·ª©c ƒë·ªô c·∫£nh b√°o Cao (ƒê·ªè). Gi√° tr·ªã m√¥ h√¨nh c√≥ t√≠nh ·ªïn ƒë·ªãnh th·∫•p},
    }""",       
    
    "result_psi_model" :
    """B√†i ki·ªÉm th·ª≠: PSI (ƒê·ªô ·ªïn ƒë·ªãnh),
    ƒê√°nh gi√° k·∫øt qu·∫£ b√†i ki·ªÉm th·ª≠ : {
        C·∫£nh b√°o Th·∫•p (Xanh) : {Ng∆∞·ª°ng gi√° tr·ªã : PSI nh·ªè h∆°n ho·∫∑c b·∫±ng 0.1, K·∫øt lu·∫≠n : M·ª©c ƒë·ªô c·∫£nh b√°o Th·∫•p (Xanh). Gi√° tr·ªã m√¥ h√¨nh c√≥ t√≠nh ·ªïn ƒë·ªãnh cao},
        C·∫£nh b√°o Trung b√¨nh (V√†ng) : {Ng∆∞·ª°ng gi√° tr·ªã : PSI l·ªõn h∆°n 0.1 v√† nh·ªè h∆°n ho·∫∑c b·∫±ng 0.3, K·∫øt lu·∫≠n : M·ª©c ƒë·ªô c·∫£nh b√°o Trung b√¨nh (V√†ng). Gi√° tr·ªã m√¥ h√¨nh c√≥ t√≠nh ·ªïn ƒë·ªãnh trung b√¨nh},
        C·∫£nh b√°o Cao (ƒê·ªè) : {Ng∆∞·ª°ng gi√° tr·ªã : PSI l·ªõn h∆°n 0.3, K·∫øt lu·∫≠n : M·ª©c ƒë·ªô c·∫£nh b√°o Cao (ƒê·ªè). Gi√° tr·ªã m√¥ h√¨nh c√≥ t√≠nh ·ªïn ƒë·ªãnh th·∫•p},
    }""",   
    
    "result_ar_model" :
    """B√†i ki·ªÉm th·ª≠: AR (Hi·ªáu nƒÉng),
    ƒê√°nh gi√° k·∫øt qu·∫£ b√†i ki·ªÉm th·ª≠ : {
        C·∫£nh b√°o Th·∫•p (Xanh) : {Ng∆∞·ª°ng gi√° tr·ªã : AR l·ªõn h∆°n ho·∫∑c b·∫±ng 0.5, K·∫øt lu·∫≠n : M·ª©c ƒë·ªô c·∫£nh b√°o Th·∫•p (Xanh). M√¥ h√¨nh c√≥ kh·∫£ nƒÉng ph√¢n bi·ªát t·ªët},
        C·∫£nh b√°o Trung b√¨nh (V√†ng) : {Ng∆∞·ª°ng gi√° tr·ªã : AR l·ªõn h∆°n ho·∫∑c b·∫±ng 0.25 v√† nh·ªè h∆°n 0.5, K·∫øt lu·∫≠n : M·ª©c ƒë·ªô c·∫£nh b√°o Trung b√¨nh (V√†ng). M√¥ h√¨nh c√≥ kh·∫£ nƒÉng ph√¢n bi·ªát trung b√¨nh},
        C·∫£nh b√°o Cao (ƒê·ªè) : {Ng∆∞·ª°ng gi√° tr·ªã : AR nh·ªè h∆°n 0.25, K·∫øt lu·∫≠n : M·ª©c ƒë·ªô c·∫£nh b√°o Cao (ƒê·ªè). M√¥ h√¨nh c√≥ kh·∫£ nƒÉng ph√¢n bi·ªát th·∫•p},
    }""" 
}

# T·∫°o c√°c c√¢u l·ªánh query cho t·ª´ng m√¥ h√¨nh
all_query = []
segmentation_col = 'Ph√¢n kh√∫c'
component_col = 'C·∫•u ph·∫ßn m√¥ h√¨nh'
for test_case in df:
    df_by_testcase = df[test_case].ffill()
    for test_segment in df_by_testcase[segmentation_col].unique():
        df_by_segment = df_by_testcase[df_by_testcase[segmentation_col] == test_segment]

        query = Introduction + "Ng∆∞·ª°ng ƒë√°nh gi√°: " + str(threshold[test_case]) + Command + "K·∫øt qu·∫£ m√¥ h√¨nh " + test_segment +':\n' 
        for i in range(len(df_by_segment)):
            query += 'C·∫•u ph·∫ßn m√¥ h√¨nh: ' + df_by_segment[component_col].values[i] + ": " + df_by_segment.columns[2] + " = " + str(df_by_segment.iloc[i, 2]) + ', ' + df_by_segment.columns[3] + " = " + str(df_by_segment.iloc[i, 3]) + ", \n"
        query += 'Ch·ªâ vi·∫øt m·ªôt c√¢u k·∫øt lu·∫≠n t·ªïng qu√°t cho k·∫øt qu·∫£ m√¥ h√¨nh n√†y, c√°c s·ªë d·∫´n ch·ª©ng vi·∫øt d∆∞·ªõi d·∫°ng ph·∫ßn trƒÉm v√† c√≥ hai ch·ªØ s·ªë sau d·∫•u ch·∫•m (V√≠ d·ª•: 10.34%).'
        all_query.append([test_case, test_segment, query])

list_query = pd.DataFrame(all_query).reset_index(drop=True)
list_query.rename(columns={0: 'Test', 1: 'Component', 2: 'Query'}, inplace=True)



result_query = []
for i in stqdm(list_query.index):
    print(list_query['Test'][i] + list_query['Component'][i])
    text_ = ask(client, mess=list_query['Query'][i])
    result_query.append(text_)

# T·∫°o tr∆∞·ªùng k·∫øt qu·∫£ theo t·ª´ng b√†i gi√°m s√°t
list_query['Results'] = result_query

for test in list_query['Test'].unique():
    print(df[test])
    values = list_query[list_query.Test == test].Results.values

    unique_values = df[test]['Ph√¢n kh√∫c'].drop_duplicates()
    mapping = dict(zip(unique_values, values))
    df[test]['K·∫øt lu·∫≠n'] = df[test]['Ph√¢n kh√∫c'].map(mapping).where(df[test]['Ph√¢n kh√∫c'].ne(df[test]['Ph√¢n kh√∫c'].shift()), '')



# Function to create an Excel file in memory
def to_excel(data):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        for sheet_name, df in data.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    return output.getvalue()

# Convert the Excel file to bytes
excel_data = to_excel(df)

@st.experimental_fragment
def download_file():
    st.download_button(
        label="Download Excel file",
        data=excel_data,
        file_name='output_gsmh.xlsx',
        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )
download_file()

st.stop()